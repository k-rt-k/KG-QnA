{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch_geometric\n",
    "\n",
    "torch.seed()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_graph import graph_to_nx\n",
    "\n",
    "G = graph_to_nx(\"IMDB-Movie-Data.csv\")\n",
    "\n",
    "data = torch_geometric.utils.from_networkx(G)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Graph Embeddings for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplEx(3659, num_relations=4, hidden_channels=64)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn.kge import ComplEx\n",
    "\n",
    "from gnn import train, lossfn, evaluate\n",
    "\n",
    "embedding_dim = 64 ## undecided\n",
    "\n",
    "num_relations = torch.max(data.type).cpu().item() + 1\n",
    "\n",
    "model = ComplEx(data.num_nodes, num_relations, hidden_channels=embedding_dim).to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "loader = model.loader(\n",
    "    head_index= data.edge_index[0],\n",
    "    rel_type= data.type,\n",
    "    tail_index= data.edge_index[1],\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3,weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.6931\n",
      "Epoch: 001, Loss: 0.6893\n",
      "Epoch: 002, Loss: 0.6468\n",
      "Epoch: 003, Loss: 0.5484\n",
      "Epoch: 004, Loss: 0.4852\n",
      "Epoch: 005, Loss: 0.4497\n",
      "Epoch: 006, Loss: 0.4174\n",
      "Epoch: 007, Loss: 0.3998\n",
      "Epoch: 008, Loss: 0.3853\n",
      "Epoch: 009, Loss: 0.3698\n",
      "Epoch: 010, Loss: 0.3588\n",
      "Epoch: 011, Loss: 0.3441\n",
      "Epoch: 012, Loss: 0.3304\n",
      "Epoch: 013, Loss: 0.3178\n",
      "Epoch: 014, Loss: 0.3031\n",
      "Epoch: 015, Loss: 0.2821\n",
      "Epoch: 016, Loss: 0.2664\n",
      "Epoch: 017, Loss: 0.2487\n",
      "Epoch: 018, Loss: 0.2260\n",
      "Epoch: 019, Loss: 0.2059\n",
      "Epoch: 020, Loss: 0.1835\n",
      "Epoch: 021, Loss: 0.1640\n",
      "Epoch: 022, Loss: 0.1483\n",
      "Epoch: 023, Loss: 0.1311\n",
      "Epoch: 024, Loss: 0.1197\n",
      "Epoch: 025, Loss: 0.1083\n",
      "Epoch: 026, Loss: 0.0967\n",
      "Epoch: 027, Loss: 0.0874\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(model,optimizer,loader)\n",
      "File \u001b[0;32m~/Desktop/Koding/Information_Retrieval/KG-QnA/gnn.py:35\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, data_loader, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m head_index, rel_type, tail_index \u001b[39min\u001b[39;00m data_loader:\n\u001b[1;32m     32\u001b[0m     \u001b[39m# x = model(head_index, rel_type, tail_index)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[39m# print(x)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 35\u001b[0m     loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mloss(head_index, rel_type, tail_index)\n\u001b[1;32m     36\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     37\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/kg/lib/python3.11/site-packages/torch_geometric/nn/kge/complex.py:82\u001b[0m, in \u001b[0;36mComplEx.loss\u001b[0;34m(self, head_index, rel_type, tail_index)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\n\u001b[1;32m     76\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     77\u001b[0m     head_index: Tensor,\n\u001b[1;32m     78\u001b[0m     rel_type: Tensor,\n\u001b[1;32m     79\u001b[0m     tail_index: Tensor,\n\u001b[1;32m     80\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 82\u001b[0m     pos_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(head_index, rel_type, tail_index)\n\u001b[1;32m     83\u001b[0m     neg_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_sample(head_index, rel_type, tail_index))\n\u001b[1;32m     84\u001b[0m     scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([pos_score, neg_score], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/kg/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/kg/lib/python3.11/site-packages/torch_geometric/nn/kge/complex.py:70\u001b[0m, in \u001b[0;36mComplEx.forward\u001b[0;34m(self, head_index, rel_type, tail_index)\u001b[0m\n\u001b[1;32m     67\u001b[0m tail_re \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_emb(tail_index)\n\u001b[1;32m     68\u001b[0m tail_im \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_emb_im(tail_index)\n\u001b[0;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m (triple_dot(head_re, rel_re, tail_re) \u001b[39m+\u001b[39m\n\u001b[1;32m     71\u001b[0m         triple_dot(head_im, rel_re, tail_im) \u001b[39m+\u001b[39m\n\u001b[1;32m     72\u001b[0m         triple_dot(head_re, rel_im, tail_im) \u001b[39m-\u001b[39m\n\u001b[1;32m     73\u001b[0m         triple_dot(head_im, rel_im, tail_re))\n",
      "File \u001b[0;32m~/anaconda3/envs/kg/lib/python3.11/site-packages/torch_geometric/nn/kge/complex.py:94\u001b[0m, in \u001b[0;36mtriple_dot\u001b[0;34m(x, y, z)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtriple_dot\u001b[39m(x: Tensor, y: Tensor, z: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mreturn\u001b[39;00m (x \u001b[39m*\u001b[39;49m y \u001b[39m*\u001b[39;49m z)\u001b[39m.\u001b[39;49msum(dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train(model,optimizer,loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
